# Model settings
MODEL_NAME=distilbert-base-multilingual-cased
MAX_LENGTH=512
NUM_LABELS=7

# Training settings
BATCH_SIZE=16
LEARNING_RATE=2e-5
NUM_EPOCHS=3
WARMUP_RATIO=0.1
WEIGHT_DECAY=0.01

# Data settings
TEST_SIZE=0.1
VAL_SIZE=0.1
MIN_TEXT_LENGTH=50
RANDOM_SEED=42

# MLflow settings
MLFLOW_TRACKING_URI=mlruns
MLFLOW_EXPERIMENT_NAME=nlp-classifier

# API settings
MODEL_PATH=/app/models/latest/final_model

# Hybrid classifier settings
CONFIDENCE_THRESHOLD=0.70
LLM_PROVIDER=groq  # Options: "groq", "anthropic", "openai"
LLM_MODEL=llama-3.3-70b-versatile  # Model to use for LLM fallback

# LLM API keys (set one based on LLM_PROVIDER)
GROQ_API_KEY=your-groq-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
OPENAI_API_KEY=your-openai-api-key-here
